{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Sentiment-model-CNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hK5hDhD-nby"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import tensorflow as tf\n",
        "from  sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo5i0PTq-ncG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31efe93-1802-4e30-899d-b34c98a45ac1"
      },
      "source": [
        "#doc du lieu ve dang data-label\n",
        "data=[]\n",
        "label=[]\n",
        "error=0\n",
        "with open('yelp_labelled.csv','r') as f:\n",
        "    for line in f:\n",
        "        part = line.strip().strip(',').split(',')\n",
        "        if len(part)<=1:\n",
        "            error+=1\n",
        "            continue\n",
        "        if part[-1]!='0' and part[-1]!='1':\n",
        "            error+=1\n",
        "            continue\n",
        "        data.append(\", \".join(part[:-1]))\n",
        "        label.append(int(part[-1]))\n",
        "print('Read',len(data),'items, skiped',error,'error lines')\n",
        "print('Label 0:',len(label)-sum(label),'Label 1:',sum(label))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 992 items, skiped 8 error lines\n",
            "Label 0: 496 Label 1: 496\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyzBDsDP-ncJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b168bd-1129-4c44-eb8c-4a1f98653bd6"
      },
      "source": [
        "print(data[:5])\n",
        "print(label[:5])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Wow... Loved this place.', 'Crust is not good.', 'Not tasty and the texture was just nasty.', 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.', 'The selection on the menu was great and so were the prices.']\n",
            "[1, 0, 0, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1L_XVK5-ncK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a1272b-63f2-4f0f-d249-9edb4905f964"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(data)\n",
        "X = tokenizer.texts_to_sequences(data)\n",
        "X = pad_sequences(X)\n",
        "print(X[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 424 164   8  15]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuF2oHsM-ncL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557c2d55-653b-4008-9ce9-a6d873191adf"
      },
      "source": [
        "print(\"input shape\",X.shape)\n",
        "n_vocab=len(tokenizer.word_index)+1\n",
        "print('Vocab count',n_vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape (992, 32)\n",
            "Vocab count 2054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwzMHmss-ncM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9bd748-5a82-4af8-f2ef-d317bfdfad10"
      },
      "source": [
        "print(n_vocab)\n",
        "print(X.shape[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2054\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5SB3VSc-ncN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c60326c-52a0-415c-e981-a2ebe4ee41b0"
      },
      "source": [
        "embedding_dim = 128\n",
        "maxlen = X.shape[1]\n",
        "vocab_size = n_vocab \n",
        "\n",
        "inputs = layers.Input(shape=( maxlen , ))\n",
        "embedding = layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)(inputs)\n",
        "\n",
        "cnn1=layers.Conv1D(128, 1, activation='relu')(embedding)\n",
        "cnn1 = layers.GlobalMaxPooling1D()(cnn1)\n",
        "\n",
        "cnn2=layers.Conv1D(128, 2, activation='relu')(embedding)\n",
        "cnn2 = layers.GlobalMaxPooling1D()(cnn2)\n",
        "\n",
        "outputs = layers.Concatenate()([cnn1,cnn2])\n",
        "\n",
        "outputs = layers.Dense(24, activation='tanh')(outputs)\n",
        "outputs = layers.Dense(12, activation='tanh')(outputs)\n",
        "outputs = layers.Dense(2, activation='softmax')(outputs)\n",
        "model=models.Model(inputs,outputs)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 32, 128)      262912      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 32, 128)      16512       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 31, 128)      32896       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           global_max_pooling1d[0][0]       \n",
            "                                                                 global_max_pooling1d_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 24)           6168        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 12)           300         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            26          dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 318,814\n",
            "Trainable params: 318,814\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktUHNKxN-ncO"
      },
      "source": [
        "#tÃ¡ch train test\n",
        "Y = tf.keras.utils.to_categorical(label)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 36)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt72tLDo-ncP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8990057b-45f7-4241-cc66-886d95d5883d"
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "38/38 [==============================] - 2s 28ms/step - loss: 0.6873 - accuracy: 0.5425 - val_loss: 0.6505 - val_accuracy: 0.6492\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.5603 - accuracy: 0.8507 - val_loss: 0.4910 - val_accuracy: 0.7823\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2585 - accuracy: 0.9528 - val_loss: 0.4207 - val_accuracy: 0.8024\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.1021 - accuracy: 0.9804 - val_loss: 0.4415 - val_accuracy: 0.8105\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.0470 - accuracy: 0.9985 - val_loss: 0.4635 - val_accuracy: 0.8226\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0300 - accuracy: 0.9980 - val_loss: 0.4976 - val_accuracy: 0.8145\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8266\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.8266\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5610 - val_accuracy: 0.8226\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.8226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCNoSoNu-ncQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a5593a-56f3-427b-c5c1-ea1bada94bae"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 1.0000\n",
            "Testing Accuracy:  0.8226\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}